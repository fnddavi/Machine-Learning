{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d53d615",
   "metadata": {},
   "source": [
    "## Exercício Redes Neurais Artificiais\n",
    "\n",
    "Instruções:\n",
    "Treinar uma Rede Neural Artificial do tipo Perceptron Multilayer para predizer os dados se um determinado paciente está doente ou não, com base em sintomas associados à doenças do coração.\n",
    "\n",
    "Para tanto, a base de dados disponível no seguinte repositório deverá ser utilizada:  Heart_disease_statlog.csv.\n",
    "\n",
    "O exercício deve ser entregue com o código fonte em Python utilizado para treinamento e teste da rede, bem como com as informações dos melhores hiperparêmetros utilizados e as métricas de desempenho obtidas. Os gráficos contendo as curvas de aprendizado também deverão ser disponibilizados.\n",
    "\n",
    "    Na elaboração do exercício, atentar para:\n",
    "    1. a necessidade de separar o conjunto de dados entre treinamento, validação e testes.\n",
    "    2. normalizar os dados de entrada, sempre que julgar necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13336b",
   "metadata": {},
   "source": [
    "### Importações e carregamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb04ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "# Carregar o CSV\n",
    "df = pd.read_csv('Heart_disease_statlog.csv')\n",
    "print(\"Primeiras 5 linhas do dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nInformações gerais do dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef860b0",
   "metadata": {},
   "source": [
    "### Verifica nulos e distribui classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verificação de valores nulos:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nShape do dataset: {df.shape}\")\n",
    "print(f\"Número de features: {df.shape[1] - 1}\")\n",
    "\n",
    "# Visualizar distribuição das classes\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title(\"Distribuição das classes (0 = saudável, 1 = doente)\")\n",
    "plt.xlabel(\"Classe\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDistribuição das classes:\")\n",
    "print(df['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d15332",
   "metadata": {},
   "source": [
    "### Separação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e29468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features e alvo\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"Shape das features: {X.shape}\")\n",
    "print(f\"Shape do target: {y.shape}\")\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Divisão treino/validação/teste: 60% treino, 20% validação, 20% teste\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "print(f\"\\nDivisão dos dados:\")\n",
    "print(f\"Treino: {X_train.shape[0]} amostras ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Validação: {X_val.shape[0]} amostras ({X_val.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Teste: {X_test.shape[0]} amostras ({X_test.shape[0]/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb58d3d",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),  # pode testar (50,), (100,50), etc.\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "print(\"Iniciando treinamento da rede neural...\")\n",
    "mlp.fit(X_train, y_train)\n",
    "print(f\"Treinamento concluído em {mlp.n_iter_} iterações\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f3db5",
   "metadata": {},
   "source": [
    "### Curvas de aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb65088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mlp.loss_curve_, 'b-', linewidth=2)\n",
    "plt.title(\"Curva de Perda durante o Treinamento\", fontsize=14)\n",
    "plt.xlabel(\"Épocas\", fontsize=12)\n",
    "plt.ylabel(\"Perda (Loss)\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Perda final: {mlp.loss_curve_[-1]:.6f}\")\n",
    "print(f\"Número de iterações: {mlp.n_iter_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95777522",
   "metadata": {},
   "source": [
    "### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af46610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predições\n",
    "y_val_pred = mlp.predict(X_val)\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "# Avaliação no conjunto de validação\n",
    "print(\"=== RESULTADOS NO CONJUNTO DE VALIDAÇÃO ===\")\n",
    "print(f\"Acurácia: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "print(\"\\nRelatório de classificação:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "print(\"\\n=== RESULTADOS NO CONJUNTO DE TESTE ===\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(\"\\nRelatório de classificação:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Matriz de Confusão\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Validação\n",
    "ConfusionMatrixDisplay.from_predictions(y_val, y_val_pred, ax=ax1, cmap='Blues')\n",
    "ax1.set_title(\"Matriz de Confusão - Validação\")\n",
    "\n",
    "# Teste\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred, ax=ax2, cmap='Blues')\n",
    "ax2.set_title(\"Matriz de Confusão - Teste\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
